{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport pytesseract as pt\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport xml.etree.ElementTree as xet\n\nfrom glob import glob\nfrom skimage import io\nfrom shutil import copy\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Input\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = glob('../input/number-plate-detection/images/*.xml')\nlabels_dict = dict(filepath=[],xmin=[],xmax=[],ymin=[],ymax=[])\nfor filename in path:\n\n    info = xet.parse(filename)\n    root = info.getroot()\n    member_object = root.find('object')\n    labels_info = member_object.find('bndbox')\n    xmin = int(labels_info.find('xmin').text)\n    xmax = int(labels_info.find('xmax').text)\n    ymin = int(labels_info.find('ymin').text)\n    ymax = int(labels_info.find('ymax').text)\n\n    labels_dict['filepath'].append(filename)\n    labels_dict['xmin'].append(xmin)\n    labels_dict['xmax'].append(xmax)\n    labels_dict['ymin'].append(ymin)\n    labels_dict['ymax'].append(ymax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(labels_dict)\ndf.to_csv('labels.csv',index=False)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = df['filepath'][0]\ndef getFilename(filename):\n    filename_image = xet.parse(filename).getroot().find('filename').text\n    filepath_image = os.path.join('../input/number-plate-detection/images',filename_image)\n    return filepath_image\ngetFilename(filename)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = list(df['filepath'].apply(getFilename))\nimage_path[:10]#random check","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = image_path[87] #path of our image N2.jpeg\nimg = cv2.imread(file_path) #read the image\n# xmin-1804/ymin-1734/xmax-2493/ymax-1882 \nimg = io.imread(file_path) #Read the image\nfig = px.imshow(img)\nfig.update_layout(width=600, height=500, margin=dict(l=10, r=10, b=10, t=10),xaxis_title='Figure 8 - N2.jpeg with bounding box')\nfig.add_shape(type='rect',x0=1804, x1=2493, y0=1734, y1=1882, xref='x', yref='y',line_color='cyan')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Targeting all our values in array selecting all columns\nlabels = df.iloc[:,1:].values\ndata = []\noutput = []\nfor ind in range(len(image_path)):\n    image = image_path[ind]\n    img_arr = cv2.imread(image)\n    h,w,d = img_arr.shape\n    # Prepprocesing\n    load_image = load_img(image,target_size=(224,224))\n    load_image_arr = img_to_array(load_image)\n    norm_load_image_arr = load_image_arr/255.0 # Normalization\n    # Normalization to labels\n    xmin,xmax,ymin,ymax = labels[ind]\n    nxmin,nxmax = xmin/w,xmax/w\n    nymin,nymax = ymin/h,ymax/h\n    label_norm = (nxmin,nxmax,nymin,nymax) # Normalized output\n    # Append\n    data.append(norm_load_image_arr)\n    output.append(label_norm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert data to array\nX = np.array(data,dtype=np.float32)\ny = np.array(output,dtype=np.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing set using sklearn.\nx_train,x_test,y_train,y_test = train_test_split(X,y,train_size=0.8,random_state=0)\nx_train.shape,x_test.shape,y_train.shape,y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inception_resnet = InceptionResNetV2(weights=\"imagenet\",include_top=False, input_tensor=Input(shape=(224,224,3)))\n# ---------------------\nheadmodel = inception_resnet.output\nheadmodel = Flatten()(headmodel)\nheadmodel = Dense(500,activation=\"relu\")(headmodel)\nheadmodel = Dense(250,activation=\"relu\")(headmodel)\nheadmodel = Dense(4,activation='sigmoid')(headmodel)\n\n\n# ---------- model\nmodel = Model(inputs=inception_resnet.input,outputs=headmodel)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Complie model\nmodel.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfb = TensorBoard('object_detection')\nhistory = model.fit(x=x_train,y=y_train,batch_size=10,epochs=180,\n                    validation_data=(x_test,y_test),callbacks=[tfb])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('./object_detection.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model\nmodel = tf.keras.models.load_model('./object_detection.h5')\nprint('Model loaded Sucessfully')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/number-plate-detection/TEST/TEST.jpeg'\nimage = load_img(path) # PIL object\nimage = np.array(image,dtype=np.uint8) # 8 bit array (0,255)\nimage1 = load_img(path,target_size=(224,224))\nimage_arr_224 = img_to_array(image1)/255.0  # Convert into array and get the normalized output\n\n# Size of the orginal image\nh,w,d = image.shape\nprint('Height of the image =',h)\nprint('Width of the image =',w)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.imshow(image)\nfig.update_layout(width=700, height=500,  margin=dict(l=10, r=10, b=10, t=10), xaxis_title='Figure 13 - TEST Image')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_arr_224.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_arr = image_arr_224.reshape(1,224,224,3)\ntest_arr.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions\ncoords = model.predict(test_arr)\ncoords","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Denormalize the values\ndenorm = np.array([w,w,h,h])\ncoords = coords * denorm\ncoords","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coords = coords.astype(np.int32)\ncoords","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Draw bounding on top the image\nxmin, xmax,ymin,ymax = coords[0]\npt1 =(xmin,ymin)\npt2 =(xmax,ymax)\nprint(pt1, pt2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv2.rectangle(image,pt1,pt2,(0,255,0),3)\nfig = px.imshow(image)\nfig.update_layout(width=700, height=500, margin=dict(l=10, r=10, b=10, t=10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create pipeline\npath = '../input/number-plate-detection/TEST/TEST.jpeg'\ndef object_detection(path):\n    \n    # Read image\n    image = load_img(path) # PIL object\n    image = np.array(image,dtype=np.uint8) # 8 bit array (0,255)\n    image1 = load_img(path,target_size=(224,224))\n    \n    # Data preprocessing\n    image_arr_224 = img_to_array(image1)/255.0 # Convert to array & normalized\n    h,w,d = image.shape\n    test_arr = image_arr_224.reshape(1,224,224,3)\n    \n    # Make predictions\n    coords = model.predict(test_arr)\n    \n    # Denormalize the values\n    denorm = np.array([w,w,h,h])\n    coords = coords * denorm\n    coords = coords.astype(np.int32)\n    \n    # Draw bounding on top the image\n    xmin, xmax,ymin,ymax = coords[0]\n    pt1 =(xmin,ymin)\n    pt2 =(xmax,ymax)\n    print(pt1, pt2)\n    cv2.rectangle(image,pt1,pt2,(0,255,0),3)\n    return image, coords\n\nimage, cods = object_detection(path)\n\nfig = px.imshow(image)\nfig.update_layout(width=700, height=500, margin=dict(l=10, r=10, b=10, t=10),xaxis_title='Figure 14')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = np.array(load_img(path))\nxmin ,xmax,ymin,ymax = cods[0]\nroi = img[ymin:ymax,xmin:xmax]\nfig = px.imshow(roi)\nfig.update_layout(width=350, height=250, margin=dict(l=10, r=10, b=10, t=10),xaxis_title='Figure 15 Cropped image')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract text from image\ntext = pt.image_to_string(roi)\nprint(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# parsing\ndef parsing(path):\n    parser = xet.parse(path).getroot()\n    name = parser.find('filename').text\n    filename = f'../input/number-plate-detection/images/{name}'\n\n    # width and height\n    parser_size = parser.find('size')\n    width = int(parser_size.find('width').text)\n    height = int(parser_size.find('height').text)\n    \n    return filename, width, height\ndf[['filename','width','height']] = df['filepath'].apply(parsing).apply(pd.Series)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now the next step is let me calculate the center_x, center_y, width and height, which is normalized to width and height. And as well normalize width and height of bounding box.","metadata":{}},{"cell_type":"code","source":"# center_x, center_y, width , height\ndf['center_x'] = (df['xmax'] + df['xmin'])/(2*df['width'])\ndf['center_y'] = (df['ymax'] + df['ymin'])/(2*df['height'])\n\ndf['bb_width'] = (df['xmax'] - df['xmin'])/df['width']\ndf['bb_height'] = (df['ymax'] - df['ymin'])/df['height']\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -r ./yolov5/requirements.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /kaggle/working/yolov5/data_images/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /kaggle/working/yolov5/data_images/test/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /kaggle/working/yolov5/data_images/train/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### split the data into train and test\ndf_train = df.iloc[:200]\ndf_test = df.iloc[200:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_folder = './yolov5/data_images/train'\n\nvalues = df_train[['filename','center_x','center_y','bb_width','bb_height']].values\nfor fname, x,y, w, h in values:\n    image_name = os.path.split(fname)[-1]\n    txt_name = os.path.splitext(image_name)[0]\n    \n    dst_image_path = os.path.join(train_folder,image_name)\n    dst_label_file = os.path.join(train_folder,txt_name+'.txt')\n    \n    # copy each image into the folder\n    copy(fname,dst_image_path)\n\n    # generate .txt which has label info\n    label_txt = f'0 {x} {y} {w} {h}'\n    with open(dst_label_file,mode='w') as f:\n        f.write(label_txt)\n        \n        f.close()\n\ntest_folder = './yolov5/data_images/test'\n\nvalues = df_test[['filename','center_x','center_y','bb_width','bb_height']].values\nfor fname, x,y, w, h in values:\n    image_name = os.path.split(fname)[-1]\n    txt_name = os.path.splitext(image_name)[0]\n    \n    dst_image_path = os.path.join(test_folder,image_name)\n    dst_label_file = os.path.join(test_folder,txt_name+'.txt')\n    \n    # copy each image into the folder\n    copy(fname,dst_image_path)\n\n    # generate .txt which has label info\n    label_txt = f'0 {x} {y} {w} {h}'\n    with open(dst_label_file,mode='w') as f:\n        f.write(label_txt)\n        \n        f.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install GPUtil\n\nimport torch\nfrom GPUtil import showUtilization as gpu_usage\nfrom numba import cuda\n\ndef free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    gpu_usage()                             \n\n    torch.cuda.empty_cache()\n\n    cuda.select_device(0)\n    cuda.close()\n    cuda.select_device(0)\n\n    print(\"GPU Usage after emptying the cache\")\n    gpu_usage()\n\nfree_gpu_cache()  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python ./yolov5/train.py --data ../input/number-plate-detection/data.yaml --cfg ./yolov5/models/yolov5s.yaml --batch-size 8 --name Model --epochs 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python ./yolov5/export.py --weight ./yolov5/runs/train/Model/weights/best.pt --include torchscript onnx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# settings\nINPUT_WIDTH =  640\nINPUT_HEIGHT = 640","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LOAD THE IMAGE\nimg = io.imread('../input/number-plate-detection/TEST/TEST.jpeg')\n\nfig = px.imshow(img)\nfig.update_layout(width=700, height=400, margin=dict(l=10, r=10, b=10, t=10))\nfig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LOAD YOLO MODEL\nnet = cv2.dnn.readNetFromONNX('./yolov5/runs/train/Model/weights/best.onnx')\nnet.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\nnet.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_detections(img,net):\n    # 1.CONVERT IMAGE TO YOLO FORMAT\n    image = img.copy()\n    row, col, d = image.shape\n\n    max_rc = max(row,col)\n    input_image = np.zeros((max_rc,max_rc,3),dtype=np.uint8)\n    input_image[0:row,0:col] = image\n\n    # 2. GET PREDICTION FROM YOLO MODEL\n    blob = cv2.dnn.blobFromImage(input_image,1/255,(INPUT_WIDTH,INPUT_HEIGHT),swapRB=True,crop=False)\n    net.setInput(blob)\n    preds = net.forward()\n    detections = preds[0]\n    \n    return input_image, detections\n\ndef non_maximum_supression(input_image,detections):\n    \n    # 3. FILTER DETECTIONS BASED ON CONFIDENCE AND PROBABILIY SCORE\n    \n    # center x, center y, w , h, conf, proba\n    boxes = []\n    confidences = []\n\n    image_w, image_h = input_image.shape[:2]\n    x_factor = image_w/INPUT_WIDTH\n    y_factor = image_h/INPUT_HEIGHT\n\n    for i in range(len(detections)):\n        row = detections[i]\n        confidence = row[4] # confidence of detecting license plate\n        if confidence > 0.4:\n            class_score = row[5] # probability score of license plate\n            if class_score > 0.25:\n                cx, cy , w, h = row[0:4]\n\n                left = int((cx - 0.5*w)*x_factor)\n                top = int((cy-0.5*h)*y_factor)\n                width = int(w*x_factor)\n                height = int(h*y_factor)\n                box = np.array([left,top,width,height])\n\n                confidences.append(confidence)\n                boxes.append(box)\n\n    # 4.1 CLEAN\n    boxes_np = np.array(boxes).tolist()\n    confidences_np = np.array(confidences).tolist()\n    \n    # 4.2 NMS\n    index = cv2.dnn.NMSBoxes(boxes_np,confidences_np,0.25,0.45)\n    \n    return boxes_np, confidences_np, index\n\ndef drawings(image,boxes_np,confidences_np,index):\n    # 5. Drawings\n    for ind in index:\n        x,y,w,h =  boxes_np[ind]\n        bb_conf = confidences_np[ind]\n        conf_text = 'plate: {:.0f}%'.format(bb_conf*100)\n        license_text = extract_text(image,boxes_np[ind])\n\n\n        cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,255),2)\n        cv2.rectangle(image,(x,y-30),(x+w,y),(255,0,255),-1)\n        cv2.rectangle(image,(x,y+h),(x+w,y+h+25),(0,0,0),-1)\n\n\n        cv2.putText(image,conf_text,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,255,255),1)\n        cv2.putText(image,license_text,(x,y+h+27),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,0),1)\n\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions flow with return result\ndef yolo_predictions(img,net):\n    # step-1: detections\n    input_image, detections = get_detections(img,net)\n    # step-2: NMS\n    boxes_np, confidences_np, index = non_maximum_supression(input_image, detections)\n    # step-3: Drawings\n    result_img = drawings(img,boxes_np,confidences_np,index)\n    return result_img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extrating text\ndef extract_text(image,bbox):\n    x,y,w,h = bbox\n    roi = image[y:y+h, x:x+w]\n    \n    if 0 in roi.shape:\n        return 'no number'\n    \n    else:\n        text = pt.image_to_string(roi)\n        text = text.strip()\n        \n        return text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test\nimg = io.imread('../input/number-plate-detection/TEST/TEST.jpeg')\nresults = yolo_predictions(img,net)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.imshow(img)\nfig.update_layout(width=700, height=400, margin=dict(l=10, r=10, b=10, t=10))\nfig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}